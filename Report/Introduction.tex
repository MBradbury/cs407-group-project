% !TeX root = Report.tex
\section{Introduction}

\subsection{What is a Wireless Sensor Network?}

A wireless sensor network, or WSN for short, is a collection of networked sensors called Motes; these sensors are capable of short range wireless communication and they have the ability to sense their surrounding environment\cite{Mica2002,TankBible}. The network forms a distributed system that can perform a variety of distributed algorithms, usually data gathering and similar tasks. To communicate, each node is equipped with a radio that allows them to send and receive messages to neighbouring nodes within a limited range. To sense the environment motes typically have a range of embedded sensors such as heat, light, humidity and many others. They typically contain a simple central processing unit (CPU), which is programmed to control the hardware on the motes. The CPU also processes events which are triggered by the hardware (such as messages being sent and received) and it also handles any other computation necessary for the operation of the system. As the platform is designed to be mobile the motes do not operate on a mains power supply, instead they run off stored energy in a battery. WSNs is a field of Computer Science that is currently the focus of much research and wireless sensor networks have a wide range of practical applications that stretch from battlefield intelligence for the military\cite{Akyildiz2002393,1368897,1457970} to industrial process monitoring for manufacturing companies\cite{?}.

A defining characteristic of designing applications for wireless sensor networks is the restricted and finite energy supply available to each node. Therefore, wireless sensor nodes tend not to use expensive broadcasting protocols such as IEEE 802.11 \cite{Mica2002}, but instead use much simpler alternatives to save energy. For example wireless protocols such as IEEE 802.15.4 ZigBee \cite{1253873, 4014617} are designed to be used by wireless sensor networks and have a lower energy usage associated with them. Some applications rely on even lower level behaviour specified by a certain MAC layer \cite{5751321,4469515,Polastre:2004:VLP:1031495.1031508,1019408,Buettner:2006:XSP:1182807.1182838}, these applications involve a trade-off between development time and energy usage. Where simplicity is often sacrificed for decreased energy usage. Using these simple protocols unfortunately has the downside of meaning that broadcasts are subject to several types of collisions and message losses. So it is very important that the software running on the nodes is designed to handle these cases. Being battery powered means that development of applications for Wireless Sensor Networks is fundamentally limited to maximising the system's lifetime so that the highest utility can be achieved from the network.

As wireless sensor nodes operate in harsh outdoors condition\cite{SzewczykPMC04, Werner-Allen:2006:FYV:1298455.1298491}, there is a high probability of them failing. These faults can range from hardware damage caused by environmental conditions or tampering, software bugs, or simply a denial of service caused by nodes running out of power. So algorithms and software need to be designed to handle these potential failures, otherwise they risk catastrophic failure when they encounter these issues.

Wireless sensor nodes are designed with the intention for them to operate in remote and traditionally unreachable locations with no human input for the lifetime of their operation\cite{1437066}. Given this a defining characteristic of a WSN system is that any applications developed for it must be self-configuring in nature; this is, the system must be able to organize itself and the network with no external input\cite{1368897}. Evidently, solutions to this issue are often considered hand in hand with the problem of network robustness and fault tolerance.   

While a limited energy source, self-configuration and network robustness are the predominant characteristic of a wireless sensor node, there are numerous other traits or issues that can be considered. For instance it is possible for these nodes to be mobile (for example an ad-hoc network of PDAs or motes built into soldiers helmets) \cite{4224091}, this can lead to very interesting behaviour in handling communication between these nodes.

%TODO: MORE OBSCURE WSN BEHAVIOUR CONSIDERATIONS

\subsection{The Problem - Debugging Distributed Systems}

Developing a distributed system is considered a particularly challenging task, more so than a traditional application, there are several reasons for this. Firstly, Within a distributed system multiple processes must execute in parallel, this means that variables may be updated independently or in repose to other processes which can lead to a myriad of synchronisation and timing issues that the developer must account for. Secondly, traditional programming languages are not well suited to develop distributed programs\cite{93692,345131}.

In any system, software or otherwise, developed by humans there is the potential for mistakes. Mistakes can be benign or they can cause unintended behaviour and system failures. Developing tools to detect these \emph{bugs} and notify the developer so they can be corrected is an incredibly important part of any toolchain. For example the GNU toolchain has utilities such as gdb\cite{?}, this allows developers to place breakpoints in code which will halt the programs execution at that state so that it can be examined. There are also numerous other tools that look for memory issues (valgrind\cite{Bond:2007:TBA:1297105.1297057,Nethercote:2007:SBM:1254810.1254820,seward2004valgrind}), security flaws (TOOL NAME\cite{?}) and many other classes of bugs.

Developing distributed systems is a difficult task; however, debugging these systems can be even more challenging\cite{345131}. When considering a distributed system if you want to examine the state of a system at a given point you cannot simply set a breakpoint in your local binary. The solution to this debugging is non-trivial, this is due to the difficulties that arise from distributed systems being non-deterministic in nature due to message communications \cite{1676929,Joyce:1987:MDS:13677.22723,Fagerstrom:1988:DTD:55823.55833}. Be it when the message started transmission, how long it took, if it succeeded or in what order transmissions occurred. So every time a distributed program is run it is possible for a different result to be obtained, due to the different order of execution. This goes against one of the usual assumptions of debugging traditional applications where it is assumed that one execution with a set of inputs will execute in exactly the same way again with the same set of inputs \cite{?} (i.e. determinism).

As the execution may be different each time in a distributed system it is not suitable to wait for a bug to occur, and then try to work out where it is. Rather, the system needs to be self-evaluating its state as it executes the distributed program; if a fault is detected, then the debugging tools will report the issue. One way to do this it to test if the system satisfies some global predicate, of which there has been much work to find and check different classes of these predicates \cite{553309,345831,277788}. However, of all the work that has been done, little of it has focused on wireless sensor networks where an important focus is perhaps the trade-off between accuracy and the report-ability of a predicate with the aim of reducing energy usage. In this paper we will discuss our development of just such a set of tools, we intend to focus on developing a system that can accurately evaluate predicates and provide useful information about real sensor networks running outside of a simulator.

\subsection{Related Work}

\subsubsection{Fault-Error-Failure Cycle}
%TODO: Joe: Needs Work

It should be clear that the types of predicates are important to consider when developing a predicate checking mechanism. Also important are the types of errors that these predicate checking algorithms can detect. To understand this it is first important to understand how errors can arise, which can be done by examining the fault-error-failure cycle. This cycle says that a \emph{fault} once caused by either some external influence (e.g. radiation leading to bit-flips in memory \cite{1017791}) or internal influence (e.g. code bugs) will lead to an \emph{error}, this is the \emph{activation} step. An error is the manifestation of the fault (e.g. memory holding the incorrect value). An error then leads to a \emph{failure} in the step called \emph{propagation}, the failure of the system is an observable deviation from the system's specification (e.g. allowing doors to be opened that should remain closed). It is not always the case the faults lead to errors, or errors lead to failures, sometimes multiple faults or errors are respectively required to cause a single error or failure. \cite{1335465}

There is a choice of what should be measured and checked in predicates; should faults, errors or failures be measured? Faults cannot be measured \cite{?} in a way that is possible for a mote, so they are discounted. That leaves measuring errors and failures. Typically failures would be the event being measured \cite{?} as that is what arises after an error actually causes the issue to happen. However, errors can also be measured if there is a dedicated program checking the state and comparing it to an expected state \cite{?}. For example an ECC (error correcting code) such as a Hamming Code can be used to detect and correct an error (in this case a bit-flip) in some memory after a fault (such as a voltage surge ) \cite{hamming1950error}.

Much of what has been discussed has involved transient faults such as those caused by environmental conditions, however, there is a class of faults that are a lot more common and much easier to resolve - faults caused by software bugs. These faults can lead to programs ending up in the wrong state and performing incorrectly. There has been a certain amount of work that looks into detecting traditional distributed system bugs (such as deadlock \cite{5587352,5284172}) in wireless sensor networks. However, there has been little work in looking into providing tools to aid in system debugging.

\subsubsection{Classes of Distributed Predicates}
%TODO: Joe: Needs Work

To begin with it is important to understand what predicates are relevant to distributed systems. First off we have a distinction between global and local predicates, global predicates involve taking a consistent global snapshot of the system and checking whether the snapshot satisfies the global predicate \cite{277788} and local predicates instead work with a subset of the network \cite{553309}. These predicates have also have a notion of stability, a stable predicate will remain true once it has turned true (e.g. termination), whereas unstable predicates can alternate between true and false. Finally there is a distinction between weak and strong, where a weak predicate holds if there exists an observation where the predicate is true and a strong predicate holds if it is true for all observers of the distributed computation\cite{553309,Cooper:1991:CDG:127695.122774}. Knowing what classes of predicates there are is important because when checking certain properties of a system a certain class of predicate will be required and thus a certain implementation will be needed to ensure the predicate is correctly checked. An example of this is when running an algorithm using global snapshots to detect stable predicates, that same application may not be suitable to detect unstable predicates because the predicate could switch to false and then back to true before the next snapshot.

\subsubsection{Existing Sensor Network Predicate Checking Tools}

There are a number of existing predicate checking solutions that have already been developed that are more practical focused than the aforementioned theoretical work into global predicate detection.

\paragraph{H-SEND} One of these solutions is H-SEND \cite{herbert2007adaptive}, which stands for Hierachichal SEnsor Network Debugging. H-SEND is a framework for detecting faults in sensor networks, it was designed to minimise energy consumption and be capable of handling very large networks. As part of the implementation developer must specify invariants within their code using a custom grammar, these invariants are then semi--automatically inserted during compilation. If an invariant is violated at runtime actions are taken (such as increased logging frequency, or an error message to the base station), using these responses developer can use the information to fix the software, which possibly include uploading a patched version of the firmware.

Of the invariants that can be specified, there are typically three different dichotomies: (i) Local vs. Multi--node, (ii) Stateless vs. Stateful and (iii) Compile--time vs. Run--time. The first indicates whether the predicate needs information about the node it is being evaluated on (Local) or other nodes in the network (Multi). The second is if the invariant depends on the node's execution state (Stateful) or if it doesn't (Stateless). The third indicates if the invariant involves values that are fixed at compile time (such as integer constants) or if it compares against values obtained during run-time (such as neighbouring states or previous states).

H-SEND is optimised for WSNs in a variety of ways. For example, it minimises overhead by buffering messages it needs to send, and piggybacking them on the existing network traffic. Due to the hierarchical nature of the protocol, multinode-invariants can be checked efficiently at the closest parent node with all the required information.

\paragraph{Sympathy} One of the projects that is summarised by H-SEND's authors \citeauthor{herbert2007adaptive} in \cite{herbert2007adaptive} is a method for identifying and localizing failures called Sympathy \cite{ramanathan2005sympathy}. Sympathy is intended to be run either in pre- or post-deployment environments where it collects data from distributed nodes at a sink. When insufficient data is received it is taken to imply that there exists a problem (insufficient data is component defined). The idea is that by monitoring data (both actively and passively) between components the system can identify what kind of failure occurred in a certain area of the network. Both of which are very useful when trying to debug a failure.

It does, however, have some downsides. The first is that there is assumed to be no traffic and thus no application traffic or network congestion. These are real issues especially when applying this kind of debugging to a high throughput sensor network. There are also a number of spurious failure notification, which the authors are working on reducing, by applying a Bayes engine.

\paragraph{DAIKON} Following Sympathy's attempts to implement a Bayes engine to allow learning to better help classify response messages, there has been work on being able to automatically detect invariants in a system. DAIKON \cite{daikon} is a system that uses execution traces to produce a list of likely invariants by way of automatically inferring the invariants through the use of a prototype invariant detector.

The set of dynamically detected invariants depend on observed values and the invariants are an indication of the quality of a test suite. Daikon consists of two parts; a language specific front end and a language independent interference engine. The former executes the running program and accesses its runtime state to get the required information (consist of variables and their value). This information contains a subset of relevant variables and only these are written to the trace file. A variable is considered as relevant depending on the type of invariants targeted and whether they are accessible at an instrumentation point. This forms an input to the second part of the system - the invariant inference engine - which uses machine learning techniques and produces a set of detected invariants for the program.

The main challenge with these techniques is deducing the relevance of the invariants as it depends on the programmer's experience and knowledge of the underlying system. However, these can be improved with techniques like exploiting unused polymorphism and suppressing invariants that are logically implied by other invariants. DAIKON does not require the programmer to specify invariants for the application, however, it is not designed for distributed or resource-constrained systems like WSN.

\paragraph{DIDUCE} One of the issues with DAIKON is that it only detects possible invariants, DIDUCE \cite{diduce} (Dynamic Invariant Detection $\cup$ Checking Engine (DIDUCE)) uses a similar metholody to detect the invariants, but it also evaluates them as they are detected. Machine learning is employed to dynamically generate hypotheses of invariants for a system at run-time. The invariants begin extremely strict, and are relaxed over time to allow for new correct behaviour. The machine learning aspect means that developers do not have to specify invariants themselves (as compared to H-SEND), which proves beneficial as accurately pinpointing the values necessary for fault-free operation is non-trivial \cite{?}. DIDUCE checks against the invariants continually during a program's operation and reports all violations detected at the end of the run, whereas DAIKON merely presents the user with invariants found. For all its apparent usefulness, unfortunately DIDUCE was designed for large, complex systems rather than lightweight distributed systems with constrained resources such as sensor networks.

\paragraph{NodeMD} An alternative to debugging compared to either specifying a predicate or an invariant, or using machine learning to learn what to check for is to instead look for the faults that arise after a failure has occurred. This is the approach that NodeMD \cite{NodeMD} takes, that by looking for the faults that can cause undesired behaviour bugs in the system can be identified. NodeMD supports checking a number of fault classes: stack overflow, livelock, deadlock and application-specific faults. By having an extensible framework, developers of a system can write their own fault detectors and plug them into NodeMD's framework. The authors of NodeMD point out that ``human interaction is often the only reliable way to address many software issues'', therefore, NodeMD supports recording events that occur to humans can analyse them to find out how a failure occurred. To optimise this format for sensor network, the event are stored in a custom binary format to save space and reduce the number of messages to transmit it (if it is possible to transmit).

NodeMD also has support for a number of useful features to aid in debugging, the first is a debug mode that is entered when a fault is detected. The debug mode freezes critical parts of the system to prevent the fault from leading to errors. This prevents events such as a context switch after a stack overflow that would end up being performed incorrectly. The debug mode also resets certain OS components to a safe state, so that some components (such as the radio) are usable to report the fault that was detected.

The other two useful features are support for remote debugging and an implementation of dynamic reprogramming algorithms to update the firmware across the network. The remote debugging feature allows a human to access all the available fault information of a sensor node. Parameters can be changed to expose more information when the node is queried and the potentially useful feature of telling the node to restart is also available. Overall NodeMD provides lots of insight into the low level failures in wireless sensor networks.


\subsubsection{Practical Sensor Network Deployments}


\subsubsection{Tools and Platforms}

